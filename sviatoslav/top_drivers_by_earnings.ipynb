{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ водіїв за прибутком за останній тиждень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/15 13:36:05 WARN Utils: Your hostname, DESKTOP-DP2FLCF resolves to a loopback address: 127.0.1.1; using 172.22.104.161 instead (on interface eth0)\n",
      "25/04/15 13:36:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/15 13:36:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/15 13:36:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SimpleApp\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fare_init = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data_lake/trip_fare_1.csv\")\n",
    "df_trip_init = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"../data_lake/trip_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_fare_init.columns:\n",
    "    df_fare_init = df_fare_init.withColumnRenamed(column, column.strip().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, lit\n",
    "\n",
    "df_trip = df_trip_init.filter(\n",
    "    (col(\"passenger_count\") > 0) & (col(\"passenger_count\") <= 10) &\n",
    "    (col(\"trip_time_in_secs\") > 0) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"pickup_latitude\").between(40.5, 41.0)) &\n",
    "    (col(\"dropoff_latitude\").between(40.5, 41.0)) &\n",
    "    (col(\"pickup_longitude\").between(-74.5, -73.0)) &\n",
    "    (col(\"dropoff_longitude\").between(-74.5, -73.0)) &\n",
    "    (col(\"pickup_datetime\") <= lit(\"2013-01-27\"))\n",
    ")\n",
    "\n",
    "df_fare = df_fare_init.filter(\n",
    "    (col(\"fare_amount\") >= 0) &\n",
    "    (col(\"tip_amount\") >= 0) &\n",
    "    (col(\"tolls_amount\") >= 0) &\n",
    "    (col(\"total_amount\") >= 0) &\n",
    "    ((col(\"fare_amount\") > 0) | (col(\"payment_type\") == \"NOC\")) &\n",
    "    (col(\"pickup_datetime\") <= lit(\"2013-01-27\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min, col, to_date, trunc\n",
    "\n",
    "df = df_trip.join(df_fare, on=[\"medallion\", \"hack_license\", \"pickup_datetime\", \"vendor_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, hour, when, to_date, max as Fmax, date_sub, expr, avg, round as Fround\n",
    "from pyspark.sql.functions import col, to_date, max as Fmax, date_sub, sum as Fsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_start = date_sub(lit(\"2013-01-27\"), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_week = df.withColumn(\"trip_date\", to_date(\"pickup_datetime\")) \\\n",
    "    .filter(col(\"trip_date\") >= week_start)\n",
    "\n",
    "df_top_drivers = df_last_week.groupBy(\"hack_license\").agg(\n",
    "    Fround(Fsum(\"total_amount\"), 2).alias(\"total_earnings\")\n",
    ").orderBy(col(\"total_earnings\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 13:39:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/15 13:39:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 8:====================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------+\n",
      "|hack_license                    |total_earnings|\n",
      "+--------------------------------+--------------+\n",
      "|CF4FCE3B4C70CD8639C01A9DFA0ABC36|3716.72       |\n",
      "|22CA618759C716436EA3257480199A32|3544.41       |\n",
      "|D85749E8852FCC66A990E40605607B2F|3511.93       |\n",
      "|895F9C541258B1B18B8EDD4756A845F0|3487.78       |\n",
      "|7B3DAEAD0556C7DC4BB925B0A8BED5D7|3459.44       |\n",
      "|6DFAEA426C5CB20249216ED8CC5F5C88|3414.41       |\n",
      "|80029AAD3540C25106CCF1F42F77E691|3404.38       |\n",
      "|F788E5B97DBC4DDAD7200A078C2B7FD2|3384.47       |\n",
      "|F153D0336BF48F93EC3913548164DDBD|3361.66       |\n",
      "|5649057646D8A96D95C2CD5C846D22D4|3323.36       |\n",
      "|508B0C200B7911E94E3D58151FADD644|3320.94       |\n",
      "|9138D1C926529049817DD4609AA26059|3308.89       |\n",
      "|23F5E8FB4BC7E65E825E8484A596C45C|3216.56       |\n",
      "|F49FD0D84449AE7F72F3BC492CD6C754|3214.67       |\n",
      "|A12D0BD80032D6655E8A882D31AB0F3A|3209.71       |\n",
      "|5403BEF884BCE629B039FAA36D8FA689|3171.22       |\n",
      "|66AC66EC81245F6D4AE9D2820D49212D|3169.31       |\n",
      "|847349F8845A667D9AC7CDEDD1C873CB|3155.67       |\n",
      "|9112D33A328C37CF6E8A6B364F0C6109|3140.42       |\n",
      "|621C552C35F2D9498F7A9DE3166FCF69|3139.14       |\n",
      "+--------------------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_drivers.show(20, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
